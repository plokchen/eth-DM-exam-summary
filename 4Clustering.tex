% -*- root: main.tex -*-
\section{Clustering}
\subsection*{K-means}
Pick centers to min. avg. sq. distance.\\
$L(\mu) = \displaystyle L (\mu_1,...,\mu_k) = \sum_{i=1}^N \min_{j \in \{1,...,k\}} ||x_i - \mu_j||_2^2$\\
$\mu^* = \arg \min_\mu L(\mu)$, (not convex \& NP-hard)

\subsection*{Lloyd's heuristic algorithm}
Initialize $\mu^{(0)} = [\mu_1^{(0)},...,\mu_k^{(0)}]$\\
\textbf{While not converged:}\\
1.) Assign each point to the closest center:\\
$z_i = \displaystyle \arg \min_{j\in \{1,...,k\}} ||x_i - \mu_j^{(t-1)}||_2^2$\\
2.) Update centers: $\mu_j^{(t)} = \frac{1}{n_j} \displaystyle \sum_{i:z_i=j} x_i$

\subsection*{Lloyd's properties}
Monotonic. decrease $L(\mu^{(t)})$ in each iteration.\\
Converges to local optimum.\\
Complexity: $\Theta ( n \cdot k \cdot d)$ (per iteration)

\subsection*{Online k-means}
Initialize centers randomly\\
For $t=1:N$:\\
Find closest center: $c = \arg \min_j = ||\mu_j-x_t||_2$\\
Set new center mean: $\mu_c = \mu_c + \eta_t(x_t-\mu_c)$\\
To converge to local optimum:\\
$\sum_t \eta_t=\infty, \sum_t\eta_t^2<\infty\text{ , E.g. } \eta_t = \frac{c}{t}$

\subsection*{Coresets}
$C$ is called a $(k, \epsilon)$-coreset for $D$, if for all $\mu:$\\
$(1-\epsilon) L_k(\mu;D) \leq L_k(\mu;C) \leq (1+\epsilon) L_k(\mu;D)$\\
where\\
$\textbf{}L_k(\mu;C) = \sum_{(w,x)\in C} w \cdot \min_{j \in \{1,...,k\}} ||\mu_j-x||_2^2$

\subsection*{Importance sampling}
$L(\mu;D) = \sum_{i=1}^N \min_j ||x_i-\mu_j||^2_2 = \sum_{i=1}^N d(x_i,\mu)$\\
$=\sum_{i=1}^N \frac{1}{N} (N\cdot d(x_i,\mu)) = \sum_{i=1}^N p(i) \cdot \frac{d(x_i,\mu)}{p(i)}$\\
$= \mathbb{E}_{i \sim p}\left [ \frac{d(x_i,\mu)}{p(i)} \right ] = \mathbb{E}_{i \sim q}\left [ \frac{d(x_i,\mu)}{q(i)} \right ] \approx \frac{1}{m} \sum_{j=1}^m \frac{d(x_{i_j})}{q(i_j)}$

\subsection*{Importance weights}
Sampling distribution $q(x)$\\
Weights $\gamma \propto \frac{1}{q}$

\subsection*{Sensitivity}
$\sigma (x) = \max_\mu \frac{d(x,\mu)^2}{\frac{1}{N} \sum_{i=1}^N d(x_i, \mu)}$ (Hard to compute)
Sensitivty measures the worst case effect for data point x on any clustering cost.

\subsection*{Coreset Construction}
1. $D^2$-sampling $p(x) = \frac{d(x,B)^2}{\sum_{x' \in X} d(x',B)^2}$\\
2. Importance sampling\\
$q(x) \propto \frac{\alpha d(x,B)^2}{c_\phi} + 2 \alpha \sum_{x' \in B_i} \frac{d(x',B)^2}{|B_i| c_\phi} + \frac{4 |X|}{|B_i|}$\\
where $c_\phi = \frac{1}{|X|} \sum_{x \in X} d(x,B)^2$\\
Coreset size: $O(\frac{dk^3}{\epsilon^2})$ for k-Means

\subsection*{Composition of Coresets}
\emph{Merge:} The union of $(k,\epsilon)$-coresets is a $(k,\epsilon)$-coreset.\\
\emph{Compress:} A $(k,\delta)$-coreset of a $(k,\epsilon)$-coreset is a $(k,\epsilon + \delta + \epsilon\delta)$-coreset.